{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Email_Spam_Detector.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-Ra5EmLNwe9",
        "colab_type": "code",
        "outputId": "bbb5def5-74a6-46de-ce87-3936fceca845",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "\n",
        "import os\n",
        "import string\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
        "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV \n",
        "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
        "import sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "df=pd.read_csv('spam.csv',encoding='latin-1')\n",
        "df=df.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
        "\n",
        "# df.head(5)\n",
        "\n",
        "df['v1'].replace( 'ham',0,inplace=True)\n",
        "df['v1'].replace( 'spam',1 ,inplace=True)\n",
        "\n",
        "X=df['v2']\n",
        "y=df['v1']\n",
        "\n",
        "def text_process(text):\n",
        "    '''\n",
        "    Takes in a string of text, then performs the following:\n",
        "    1. Remove all punctuation\n",
        "    2. Remove all stopwords - It decreases the precision \n",
        "    3. Return the cleaned text as a list of words\n",
        "    '''\n",
        "    nopunc = [char for char in text if char not in string.punctuation]\n",
        "    nopunc = ''.join(nopunc)\n",
        "    return [word for word in nopunc.split() if word.lower() not in ENGLISH_STOP_WORDS]\n",
        "    # return [word for word in nopunc.split() if word.lower() not in stop.split()]\n",
        "sample_text = \"Hey there! This is a sample review, which happens to contain punctuations.\"\n",
        "print(text_process(sample_text))\n",
        "\n",
        "\n",
        "\n",
        "bow_transformer = sklearn.feature_extraction.text.CountVectorizer(analyzer=text_process).fit(X)\n",
        "# bow_transformers = TfidfTransformer()\n",
        "# bow_transformers = bow_transformers.fit_transform(X)\n",
        "print(len(bow_transformer.vocabulary_))\n",
        "\n",
        "X = bow_transformer.transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=101)\n",
        "\n",
        "nb = LogisticRegression()\n",
        "nb.fit(X_train, y_train)\n",
        "preds = nb.predict(X_test)\n",
        "print(confusion_matrix(y_test,preds))\n",
        "print(accuracy_score(y_test, preds))\n",
        "\n",
        "\n",
        "svc = SVC(kernel='linear', C=1, gamma=0.001)\n",
        "svc.fit(X_train, y_train)\n",
        "prediction =svc.predict(X_test)\n",
        "print('svc:  ', accuracy_score(y_test, prediction))\n",
        "\n",
        "## for finding optimal value for hyper paramerter  for svm\n",
        "# Cs = [0.001, 0.01, 0.1, 1, 10,100,1000]\n",
        "# gammas = [0.001, 0.01, 0.1, 1]\n",
        "# param_grid = {'C': Cs, 'gamma' : gammas}\n",
        "# grid_search = GridSearchCV(SVC(kernel='linear'), param_grid, cv=5)\n",
        "# grid_search.fit(X, y)\n",
        "# grid_search.best_params_\n",
        "# print(grid_search.best_params_)\n",
        "\n",
        "\n",
        "message='''Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The '''\n",
        "\n",
        "positive_review_transformed = bow_transformer.transform([message])\n",
        "print(\"review pred: \", pd.DataFrame(nb.predict_proba(positive_review_transformed)))\n",
        "print(\"review pred: \", pd.DataFrame(nb.predict(positive_review_transformed)))\n",
        "\n",
        "rank=nb.predict(positive_review_transformed)\n",
        "ranks=svc.predict(positive_review_transformed)\n",
        "rank\n",
        "if (rank==0):\n",
        "  print('Somebody inbox to you. Please check')\n",
        "else:\n",
        "  print('Yes it is a spam mail')\n",
        "\n",
        "ranks\n",
        "if (ranks==0):\n",
        "  print('Somebody inbox to you. Please check')\n",
        "else:\n",
        "  print('Yes it is a spam mail')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Hey', 'sample', 'review', 'happens', 'contain', 'punctuations']\n",
            "11052\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[496   0]\n",
            " [ 11  51]]\n",
            "0.9802867383512545\n",
            "svc:   0.9802867383512545\n",
            "review pred:           0        1\n",
            "0  0.26192  0.73808\n",
            "review pred:     0\n",
            "0  1\n",
            "Yes it is a spam mail\n",
            "Yes it is a spam mail\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}