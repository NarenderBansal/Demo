{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Boston home price prediction.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"kNL2ptmnprvN","colab_type":"code","outputId":"9f57d62d-74c4-49d0-f26d-d1d3b565317b","executionInfo":{"status":"ok","timestamp":1578035225390,"user_tz":-330,"elapsed":1286,"user":{"displayName":"Narender Bansal","photoUrl":"","userId":"07056133008506250280"}},"colab":{"base_uri":"https://localhost:8080/","height":267}},"source":["\n","\n","from xgboost.sklearn import XGBRegressor\n","# from tpot import TPOTRegressor\n","from sklearn.ensemble import AdaBoostRegressor,RandomForestRegressor,GradientBoostingRegressor\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.linear_model import ElasticNetCV,RidgeCV\n","from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n","import numpy as np\n","import pandas as pd\n","import scipy.stats as stats\n","import matplotlib.pyplot as plt\n","import sklearn\n","#import statsmodels.api as sm\n","from sklearn.datasets import load_boston\n","from sklearn.linear_model import LinearRegression,LogisticRegression\n","from sklearn import model_selection\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split \n","from sklearn.metrics import mean_squared_error,r2_score,accuracy_score\n","import pickle\n","\n","boston = load_boston(return_X_y=False)\n","bos = pd.DataFrame(boston.data)\n","\n","names = ['CRIM',  'ZN',  'INDUS' , 'CHAS' , 'NOX',  'RM'  ,'AGE' , 'DIS',  'RAD',  'TAX',  'PTRATIO',   'B',  'LSTAT']\n","test=['Price']\n","X= pd.DataFrame(boston.data,columns=names).values\n","y= pd.DataFrame(boston.target,columns =test).values\n","\n","df=pd.DataFrame(boston.data,columns=names)\n","df1=pd.DataFrame(boston.target,columns =test)\n","\n","\n","\n","\n","#print(df.head(5))\n","\n","#print(df.AGE.unique)\n","\n","# from sklearn.model_selection import train_test_split \n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.23, \n","                                                   random_state=4)\n","\n","regr = LinearRegression() \n","   \n","# Train the model using the training sets \n","regr.fit(X_train, y_train)\n","\n","\n","\n","# with open('LinearRegression.pickle', 'wb') as handle:\n","#   pickle.dump(regr, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","# with open('TpotRegression.pickle', 'rb') as handle:\n","# \ttpot = pickle.load(handle)\n","  \n","# with open('LinearRegression.pickle', 'rb') as handle:\n","# \tregr = pickle.load(handle)\n","\n","preds=regr.predict(X_test)\n","sub1 = pd.DataFrame(data=preds)  \n","\n","\n","print('Accuracy:', regr.score(X,y))\n","#print('Accuracys:',accuracy_score(X.round(),y.round(),normalize=False))\n","\n","\n","print(\"Mean squared error: %.2f\" % mean_squared_error(y_test,preds))\n","\n","print(\"r2_score: %.2f\" % r2_score(y_test,preds))\n","# print(metrics.accuracy_score(y_test,preds))\n","print(metrics.explained_variance_score(y_test,preds))\n","\n","\n","rf = RandomForestRegressor(max_features=2, min_samples_split=4, n_estimators=50, min_samples_leaf=2)\n","gb = GradientBoostingRegressor(loss='quantile', learning_rate=0.0001, n_estimators=50, max_features='log2', min_samples_split=2, max_depth=1)\n","ada_tree_backing = DecisionTreeRegressor(max_features='sqrt', splitter='random', min_samples_split=4, max_depth=3)\n","ab = AdaBoostRegressor(ada_tree_backing, learning_rate=0.1, loss='square', n_estimators=2000)\n","\n","# search_grid={'n_estimators':[500,1000,2000],'learning_rate':[.001,0.01,.1],'random_state':[1]}\n","# search=GridSearchCV(estimator=ab,param_grid=search_grid,scoring='neg_mean_squared_error',n_jobs=1,cv=10)\n","# search.fit(X,y)\n","# search.best_params_ \n","\n","rf.fit(X_train, y_train)\n","preds=rf.predict(X_test)\n","gb.fit(X_train, y_train)\n","ab.fit(X_train, y_train)\n","\n","print('rf:  ',rf.score(X_test,y_test))\n","print('gb:  ',gb.score(X_test,y_test))\n","print('ab:  ',ab.score(X_test,y_test))\n","print(\"Mean squared error: %.2f\" % mean_squared_error(y_test,preds))\n","\n","# model=XGBRegressor()\n","# model.fit(X_train, y_train)\n","# print('XGB: ' ,model.score(X_test,y_test))\n","\n","# results = []\n","# kfold = model_selection.KFold(n_splits=2, random_state=4)\n","# cv_results = model_selection.cross_val_score(regr, X, y, cv=kfold, scoring='r2')\n","# results.append(cv_results)\n","# print(cv_results)\n","\n","# msg = \"%f, (%f)\" % (cv_results.mean(), cv_results.std())\n","# print(msg)\n","\n","\n","# # tpot = TPOTRegressor(generations=2, population_size=50, verbosity=2)\n","# # tpot.fit(X_train, y_train)\n","\n","\n","# # with open('TpotRegression.pickle', 'wb') as handle:\n","# #   pickle.dump(tpot.fitted_pipeline_, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","\n","# with open('TpotRegression.pickle', 'rb') as handle:\n","# \ttpot = pickle.load(handle)\n","\n","# tpot_pred = tpot.predict(X_test)  \n","\n","# print(tpot.score(X_test, y_test))\n","\n","# # tpot.export('tpot_boston_pipeline.py')\n","\n","# print(\"Mean squared error: %.2f\" % mean_squared_error(y_test,tpot_pred))\n","\n","# results = []\n","# kfold = model_selection.KFold(n_splits=2, random_state=4)\n","# cv_results = model_selection.cross_val_score(regr, X, y, cv=kfold, scoring='r2')\n","# results.append(cv_results)\n","# print(cv_results)\n","\n","# msg = \"%f, (%f)\" % (cv_results.mean(), cv_results.std())\n","# print(msg)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Accuracy: 0.7386930479691552\n","Mean squared error: 25.93\n","r2_score: 0.73\n","0.7336806302136071\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:86: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"],"name":"stderr"},{"output_type":"stream","text":["rf:   0.8522155568471593\n","gb:   -0.8765504160346512\n","ab:   0.5242535954790446\n","Mean squared error: 14.33\n"],"name":"stdout"}]}]}